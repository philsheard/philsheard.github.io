---
created: 2024-06-23T12:26:51+01:00
modified: 2024-06-23T12:42:54+01:00
date: 2024-06-23
published: true
title: Research into scientific papers identifies some LLM giveaways
---

Interesting article on Hacker news over the weekend: [Delving into ChatGPT usage in academic writing through excess vocabulary](https://news.ycombinator.com/item?id=40763133)

Researchers [analysed over a decade of academic research abstracts](https://arxiv.org/abs/2406.07016) and looked for words that had risen significantly since the widespread usage of LLMs in 2022 when ChatGPT launched. Their results show up a few words that have suddently spiked in usage, giving us pointers about what language ticks an LLM is likely to introduce and also gives an indication of how widespread usage of ChatGPT was in submissions (answer: average 10% of papers, with up to 30% in some categories).

The words they identified include "delve", "showcase" and "potential". Importantly these aren't new words to the language, but they were not so popular in academic research before widespread adoption of LLMs so the increase stands out.

[One of the replies](https://news.ycombinator.com/item?id=40763577) to the post on Hacker News observes that LLMs are trained on public content that can disproportionately feature marketing materials compared to actual conversational language. Whether or not you ask for 'marketing style' writing when using an LLM to autogenerate text, you might be getting it anyway due to the natural bias of the training data.

## What might this mean for you? 
If you use an LLM to help you write, you have to be more hands-on with prompting and work harder to avoid these cliches. What's the point of using AI to improve your writing only to make it more generic and ignorable?

I'd go further and say that the average marketing or comms person without leet prompting skillz should only be using an LLM to create a rough draft or outline, and make sure that the final output feels authentically yours. In other sectors I think the risk is smaller but when you're selling communication skills, you really shouldn't be delegating that to an AI.

---

Sidenote: This is a good example of what Roger Martin has written about, [where (esp. unskilled) use of LLMs by definition leads to average results](https://rogermartin.medium.com/strategy-artificial-intelligence-6f719015b8fc).

Sidenote two: They also coined the phrase "excess vocabulary" to describe the filler words that often get added to this type of writing. AI has a tendency to waffle unless you specificall prompt to avoid this. The phrase was inspired by the similar "excess deaths" that was used during Covid times to estimate how many extra lives were lost above the typical amount forecast for that time. 

Sidenote three: I looked for a summary of this research paper online to link to and the only one I found seemed to contain an example of this AI excess vocabulary, suggesting it was itself AI generated. Oh the irony.
